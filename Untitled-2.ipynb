{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5efb6ca4",
   "metadata": {},
   "source": [
    "# Ejemplo de entrenamiento de una red neuronal simple en PyTorch utilizando el dataset MNIST de Hugging Face\n",
    "\n",
    "En este ejemplo, entrenaremos una red neuronal sencilla para clasificar imágenes de dígitos escritos a mano utilizando el dataset `mnist` de Hugging Face. Seguiremos los pasos fundamentales: descarga y exploración del dataset, preprocesamiento, definición del modelo, entrenamiento, validación y generación de predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbdb3f",
   "metadata": {},
   "source": [
    "## 1. Importar librerías necesarias\n",
    "\n",
    "Importamos PyTorch, matplotlib y las funciones de datasets de Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b290a35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d42690",
   "metadata": {},
   "source": [
    "## 2. Descargar y explorar un dataset diferente de Hugging Face\n",
    "\n",
    "Utilizaremos el dataset `mnist`, que contiene imágenes de dígitos escritos a mano (0-9). Descarguemos el dataset y exploremos su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d3e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar el dataset MNIST desde Hugging Face\n",
    "dataset = load_dataset(\"mnist\")\n",
    "\n",
    "# Mostrar las llaves y tamaños de los splits\n",
    "print(dataset)\n",
    "\n",
    "# Visualizar algunas imágenes de ejemplo\n",
    "fig, axs = plt.subplots(1, 5, figsize=(12, 3))\n",
    "for i in range(5):\n",
    "    img = dataset[\"train\"][i][\"image\"]\n",
    "    label = dataset[\"train\"][i][\"label\"]\n",
    "    axs[i].imshow(img, cmap=\"gray\")\n",
    "    axs[i].set_title(f\"Etiqueta: {label}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d378521",
   "metadata": {},
   "source": [
    "## 3. Preprocesar los datos\n",
    "\n",
    "Convertimos las imágenes a tensores, normalizamos los valores de píxeles y dividimos el dataset en entrenamiento, validación y prueba. Implementaremos una clase Dataset personalizada para adaptar el formato de Hugging Face a PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a5482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Transformación: convertir a tensor y normalizar\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convierte PIL Image a tensor [0,1]\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normaliza a [-1,1]\n",
    "])\n",
    "\n",
    "# Clase Dataset personalizada\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.dataset[idx][\"image\"]\n",
    "        label = self.dataset[idx][\"label\"]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Crear los datasets\n",
    "train_dataset = MNISTDataset(dataset[\"train\"], transform=transform)\n",
    "test_dataset = MNISTDataset(dataset[\"test\"], transform=transform)\n",
    "\n",
    "# Dividir train en train y validación (80/20)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Tamaño train: {len(train_dataset)}, validación: {len(val_dataset)}, test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311afb4f",
   "metadata": {},
   "source": [
    "## 4. Definir el modelo de red neuronal\n",
    "\n",
    "Definimos una red neuronal simple con una capa oculta y activación ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bddf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedSimple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.red = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.red(x)\n",
    "        return logits\n",
    "\n",
    "# Instanciar el modelo y mover a GPU si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo = RedSimple().to(device)\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27168bbf",
   "metadata": {},
   "source": [
    "## 5. Preparar DataLoaders para entrenamiento y validación\n",
    "\n",
    "Creamos los DataLoaders para los sets de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c120e0",
   "metadata": {},
   "source": [
    "## 6. Entrenar y validar el modelo\n",
    "\n",
    "Implementamos los bucles de entrenamiento y validación, mostrando la pérdida y la exactitud por época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.001)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += X.size(0)\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def val_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            total_loss += loss.item() * X.size(0)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += X.size(0)\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_loop(train_loader, modelo, loss_fn, optimizer)\n",
    "    val_loss, val_acc = val_loop(val_loader, modelo, loss_fn)\n",
    "    print(f\"Época {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  Entrenamiento -> Pérdida: {train_loss:.4f}, Exactitud: {train_acc*100:.2f}%\")\n",
    "    print(f\"  Validación    -> Pérdida: {val_loss:.4f}, Exactitud: {val_acc*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77586650",
   "metadata": {},
   "source": [
    "## 7. Realizar predicciones con el modelo entrenado\n",
    "\n",
    "Tomamos una muestra del set de prueba, generamos una predicción y visualizamos la imagen junto con la categoría predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar una muestra del set de prueba\n",
    "ejemplo_img, ejemplo_lbl = test_dataset[0]\n",
    "ejemplo_img_gpu = ejemplo_img.unsqueeze(0).to(device)  # Añadir dimensión batch\n",
    "\n",
    "# Generar predicción\n",
    "modelo.eval()\n",
    "with torch.no_grad():\n",
    "    logits = modelo(ejemplo_img_gpu)\n",
    "    pred = logits.argmax(1).item()\n",
    "\n",
    "plt.imshow(ejemplo_img.squeeze().cpu(), cmap=\"gray\")\n",
    "plt.title(f\"Predicción: {pred} (Etiqueta real: {ejemplo_lbl})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
